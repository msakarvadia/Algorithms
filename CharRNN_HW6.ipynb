{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharRNN - HW6",
      "provenance": [],
      "collapsed_sections": [
        "hUGtfyrbe6Fd",
        "xcYKWJPuffOV",
        "pJawX4To-NXi",
        "fBjMa6hnYLwu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2hPDx3Tvh0v"
      },
      "source": [
        "# Homework 6\n",
        "\n",
        "In this homework you will be training and using a \"char-RNN\". This is the name given to a character-level recurrent neural network language model by [this famous blog post by Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Before you start on the rest of the homework, please give the blog post a read, it's quite good!\n",
        "\n",
        "I don't expect you to implement the char-RNN from scratch. Andrej's original char-rnn is in Torch (the predecessor to PyTorch that is not commonly used anymore). Fortunately, there are many other implementations of this model available; for example, there is one (in both mxnet and pytorch) in chapters 8 and 9 of [the textbook](http://d2l.ai), and another pytorch one [here](https://github.com/spro/char-rnn.pytorch). **Please use one of these example implementations (or another one that you find) when completing this homework**.\n",
        "\n",
        "For this homework, please complete the following steps:\n",
        "\n",
        "1. Download and tokenize the [Shakespeare dataset](http://www.gutenberg.org/files/100/100-0.txt) at a character level. I recommend basing your solution on the following code:\n",
        "```Python\n",
        "# Remove non-alphabetical characters, lowercase, and replace whitespace with ' '\n",
        "raw_dataset = ' '.join(re.sub('[^A-Za-z]+','', text).lower().split())\n",
        "# Maps token index to character\n",
        "idx_to_char = list(set(raw_dataset))\n",
        "# Maps character to token index\n",
        "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
        "# Tokenize the dataset\n",
        "corpus_indices = [char_to_idx[char] for char in raw_dataset]\n",
        "```\n",
        "1. Train a \"vanilla\" RNN (as described in chapter 8 of [the textbook](http://d2l.ai)) on the Shakespeare dataset. Report the training loss and generate some samples from the model at the end of training.\n",
        "1. Train a GRU RNN (as described in chapter 9 of [the textbook](http://d2l.ai)) on the Shakespeare datatset. Is the final training loss higher or lower than the vanilla RNN? Are the samples from the model more or less realistic?\n",
        "1. Find a smaller, simpler dataset than the Shakespeare data (you can find some ideas in Andrej's blog post, but feel free to get creative!) and train either the vanilla or GRU RNN on it instead. Is the final training loss higher or lower than it was for the Shakespeare data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUGtfyrbe6Fd"
      },
      "source": [
        "# #1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAfgV9YHe5ae"
      },
      "source": [
        "!pip install -q tqdm\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5kjSTJHfIH_"
      },
      "source": [
        "import torch\r\n",
        "import math\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torchvision\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.autograd import Variable\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from IPython import display\r\n",
        "import time\r\n",
        "from string import ascii_lowercase\r\n",
        "from string import ascii_uppercase"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7dVCogafKeD"
      },
      "source": [
        "use_cuda = False"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDSV8IlfMQ5",
        "outputId": "b410419f-9ade-4f5d-ec43-9e0313077a94"
      },
      "source": [
        "import requests\r\n",
        "import string\r\n",
        "import random\r\n",
        "\r\n",
        "all_characters = string.printable\r\n",
        "n_characters = len(all_characters)\r\n",
        "\r\n",
        "def DownloadFile(url):\r\n",
        "    local_filename = url.split('/')[-1]\r\n",
        "    r = requests.get(url)\r\n",
        "    return r.text\r\n",
        "\r\n",
        "def char_tensor(string):\r\n",
        "    tensor = torch.zeros(len(string)).long()\r\n",
        "    for c in range(len(string)):\r\n",
        "        try:\r\n",
        "            tensor[c] = all_characters.index(string[c])\r\n",
        "        except:\r\n",
        "            continue\r\n",
        "    return tensor  \r\n",
        "\r\n",
        "def random_training_set(chunk_len, batch_size, file):\r\n",
        "    inp = torch.LongTensor(batch_size, chunk_len)\r\n",
        "    target = torch.LongTensor(batch_size, chunk_len)\r\n",
        "    for bi in range(batch_size):\r\n",
        "        start_index = random.randint(0, len(file) - chunk_len)\r\n",
        "        end_index = start_index + chunk_len + 1\r\n",
        "        chunk = file[start_index:end_index]\r\n",
        "        inp[bi] = char_tensor(chunk[:-1])\r\n",
        "        target[bi] = char_tensor(chunk[1:])\r\n",
        "    inp = Variable(inp)\r\n",
        "    target = Variable(target)\r\n",
        "    if use_cuda:\r\n",
        "        inp = inp.cuda()\r\n",
        "        target = target.cuda()\r\n",
        "    return inp, target\r\n",
        "\r\n",
        "def time_since(since):\r\n",
        "    s = time.time() - since\r\n",
        "    m = math.floor(s / 60)\r\n",
        "    s -= m * 60\r\n",
        "    return '%dm %ds' % (m, s)\r\n",
        "  \r\n",
        "target_url = \"https://raw.githubusercontent.com/cos495/code/master/shakespeare.txt\"\r\n",
        "data = DownloadFile(target_url)\r\n",
        "#print(random_training_set(10, 8, data))\r\n",
        "print(data[10:100])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "zen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMDDua9CfTIR"
      },
      "source": [
        "# #2 Vanilla RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOeWcraLfWEd"
      },
      "source": [
        "# https://github.com/spro/char-rnn.pytorch\r\n",
        "class CharRNN(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, output_size, model=\"rnn\", n_layers=1):\r\n",
        "        super(CharRNN, self).__init__()\r\n",
        "        self.model = model.lower()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.output_size = output_size\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\r\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\r\n",
        "        if model==\"lstm\":\r\n",
        "          self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\r\n",
        "        if model==\"gru\":\r\n",
        "          self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\r\n",
        "          \r\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\r\n",
        "\r\n",
        "    def forward(self, input, hidden):\r\n",
        "        batch_size = input.size(0)       \r\n",
        "        encoded = self.encoder(input)\r\n",
        "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\r\n",
        "        output = self.decoder(output.view(batch_size, -1))\r\n",
        "        return output, hidden\r\n",
        "\r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "        if self.model == \"lstm\":\r\n",
        "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\r\n",
        "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\r\n",
        "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcYKWJPuffOV"
      },
      "source": [
        "###Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz7WhJMIfZQJ"
      },
      "source": [
        "hidden_size = 100\r\n",
        "learning_rate = 0.01\r\n",
        "cell = \"rnn\"\r\n",
        "n_layers = 2\r\n",
        "\r\n",
        "decoder = CharRNN(\r\n",
        "    n_characters,\r\n",
        "    hidden_size,\r\n",
        "    n_characters,\r\n",
        "    model=cell,\r\n",
        "    n_layers=n_layers,\r\n",
        ")\r\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "if use_cuda:\r\n",
        "    decoder.cuda()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MluhOww7fitX"
      },
      "source": [
        "n_epochs = 2000\r\n",
        "chunk_len = 200\r\n",
        "print_every = 100\r\n",
        "batch_size = 100"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFojnv1VfkYu"
      },
      "source": [
        "def train(inp, target):\r\n",
        "    hidden = decoder.init_hidden(batch_size)\r\n",
        "    if use_cuda:\r\n",
        "        hidden = hidden.cuda()\r\n",
        "    decoder.zero_grad()\r\n",
        "    loss = 0\r\n",
        "\r\n",
        "    for c in range(chunk_len):\r\n",
        "        output, hidden = decoder(inp[:,c], hidden)\r\n",
        "        loss += criterion(output.view(batch_size, -1), target[:,c])\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    decoder_optimizer.step()\r\n",
        "\r\n",
        "    #Old version (doesn't support zero indexing)\r\n",
        "    #return loss.data[0] / chunk_len\r\n",
        "    return loss.data / chunk_len"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n5Rt47ffs7g"
      },
      "source": [
        "###Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r400OOwcfuP-"
      },
      "source": [
        "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\r\n",
        "    hidden = decoder.init_hidden(1)\r\n",
        "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\r\n",
        "\r\n",
        "    if cuda:\r\n",
        "        hidden = hidden.cuda()\r\n",
        "        prime_input = prime_input.cuda()\r\n",
        "    predicted = prime_str\r\n",
        "\r\n",
        "    # Use priming string to \"build up\" hidden state\r\n",
        "    for p in range(len(prime_str) - 1):\r\n",
        "        _, hidden = decoder(prime_input[:,p], hidden)\r\n",
        "        \r\n",
        "    inp = prime_input[:,-1]\r\n",
        "    \r\n",
        "    for p in range(predict_len):\r\n",
        "        output, hidden = decoder(inp, hidden)\r\n",
        "        \r\n",
        "        # Sample from the network as a multinomial distribution\r\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\r\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\r\n",
        "\r\n",
        "        # Add predicted character to string and use as next input\r\n",
        "        predicted_char = all_characters[top_i]\r\n",
        "        predicted += predicted_char\r\n",
        "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\r\n",
        "        if cuda:\r\n",
        "            inp = inp.cuda()\r\n",
        "\r\n",
        "    return predicted"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JnqimCkfxEH",
        "outputId": "5de32b3d-0bca-465f-fbe7-034cff05962e"
      },
      "source": [
        "start = time.time()\r\n",
        "all_losses = []\r\n",
        "loss_avg = 0\r\n",
        "\r\n",
        "print(\"Training for %d epochs...\" % n_epochs)\r\n",
        "for epoch in tqdm(range(1, n_epochs + 1)):\r\n",
        "    loss = train(*random_training_set(chunk_len, batch_size, data))\r\n",
        "    loss_avg += loss\r\n",
        "    all_losses.append(loss.item())\r\n",
        "    if epoch % print_every == 0:\r\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\r\n",
        "        print('loss: ', loss)\r\n",
        "        print(generate(decoder, 'Wh', 100, cuda=use_cuda), '\\n')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training for 2000 epochs...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [00:42<13:56,  2.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0m 42s (100 5%) 1.8123]\n",
            "loss:  tensor(1.8123)\n",
            "Where priath and nrield did\n",
            "Of in'le your grown hother thy hear not are dulse to I with thle\n",
            "I his don \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 200/2000 [01:25<13:05,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1m 25s (200 10%) 1.6499]\n",
            "loss:  tensor(1.6499)\n",
            "Why heart, sir he reack and look;\n",
            "The would where a deather ears and deverdst theal.\n",
            "\n",
            "CORIOLANUS:\n",
            "Ay h \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 300/2000 [02:08<12:21,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2m 8s (300 15%) 1.5875]\n",
            "loss:  tensor(1.5875)\n",
            "Whost and stands it rave thought thou have now, I standing better the knovendering by tilloust shall c \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 400/2000 [02:51<11:49,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2m 50s (400 20%) 1.5427]\n",
            "loss:  tensor(1.5427)\n",
            "Whose not say, methou the day fear the brink, for that should on the laper thou guetion:\n",
            "Yet this come \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 500/2000 [03:33<11:02,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3m 33s (500 25%) 1.4994]\n",
            "loss:  tensor(1.4994)\n",
            "When bead;\n",
            "If you speak, they hath some shund the be he leavens to dome his hards made that so fancent \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 600/2000 [04:16<10:07,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4m 16s (600 30%) 1.5446]\n",
            "loss:  tensor(1.5446)\n",
            "Where the sorrow your mart with that we shall would speak, and this good unchard, as our day,\n",
            "see hait \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 700/2000 [04:58<09:19,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4m 58s (700 35%) 1.5057]\n",
            "loss:  tensor(1.5057)\n",
            "Which sin; it would ever blown of her smiler madred men one till supplicing,\n",
            "That shall nays,\n",
            "Plear of \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 800/2000 [05:40<08:36,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[5m 40s (800 40%) 1.4852]\n",
            "loss:  tensor(1.4852)\n",
            "Which none inteing friend,\n",
            "And hence, in you, married?\n",
            "\n",
            "ROMEO:\n",
            "Go there hang thou wish, when thou she  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 900/2000 [06:22<07:57,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[6m 22s (900 45%) 1.4988]\n",
            "loss:  tensor(1.4988)\n",
            "Which I know, empoor may did not shall never with was no forget in your grief;\n",
            "And not come my body: a \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1000/2000 [07:05<07:12,  2.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7m 5s (1000 50%) 1.4949]\n",
            "loss:  tensor(1.4949)\n",
            "Whilst some sons the love\n",
            "Is you and africe,\n",
            "Where was this to this be curst thou follow is favours:\n",
            "C \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1100/2000 [07:47<06:28,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7m 47s (1100 55%) 1.4868]\n",
            "loss:  tensor(1.4868)\n",
            "Where mark him.\n",
            "\n",
            "ISABELLA:\n",
            "Convers with the watch, wounds good want, for your wor help but honesty.\n",
            "\n",
            "J \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1200/2000 [08:30<05:49,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[8m 30s (1200 60%) 1.4949]\n",
            "loss:  tensor(1.4949)\n",
            "What to your vuilla! one sun the desire in protors! and excenders\n",
            "beseech and to my son.\n",
            "\n",
            "GLOUCESTER:\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1300/2000 [09:13<04:59,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9m 12s (1300 65%) 1.4807]\n",
            "loss:  tensor(1.4807)\n",
            "Where with dishmas for me, what thou hath my well:\n",
            "Laids.\n",
            "\n",
            "PRINCENTE:\n",
            "What is a bid that go thee weddo \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1400/2000 [09:55<04:19,  2.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9m 55s (1400 70%) 1.4247]\n",
            "loss:  tensor(1.4247)\n",
            "Where is the preparela, and my contrame forite whom in and of scove, sir.\n",
            "\n",
            "LUCENTIO:\n",
            "Who you seed.\n",
            "\n",
            "CO \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1500/2000 [10:38<03:42,  2.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10m 38s (1500 75%) 1.4568]\n",
            "loss:  tensor(1.4568)\n",
            "Where was both's son, with\n",
            "so lame.\n",
            "\n",
            "CLAUDIO:\n",
            "Why do this women a loss to the brother's person; but to \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1600/2000 [11:20<02:54,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[11m 20s (1600 80%) 1.4682]\n",
            "loss:  tensor(1.4682)\n",
            "Whom here\n",
            "wast sads use I should in the just themsious sight!\n",
            "\n",
            "YORK:\n",
            "It is my slaughter, when me to sa \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1700/2000 [12:03<02:12,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12m 3s (1700 85%) 1.4761]\n",
            "loss:  tensor(1.4761)\n",
            "Whose our conselved unclews, stands as gather tack to term'd upon the basing of mine sadnted the other \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 1800/2000 [12:46<01:27,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12m 46s (1800 90%) 1.4941]\n",
            "loss:  tensor(1.4941)\n",
            "When these the great blow a hungrows can my house the prest\n",
            "Being set your souls be another in Kate at \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1900/2000 [13:29<00:44,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13m 29s (1900 95%) 1.4321]\n",
            "loss:  tensor(1.4321)\n",
            "What you contempt,\n",
            "Whilst you many and will not grace you in,\n",
            "break, from his complain,\n",
            "Make open to m \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [14:12<00:00,  2.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14m 12s (2000 100%) 1.4686]\n",
            "loss:  tensor(1.4686)\n",
            "Where me\n",
            "The corn with him my good\n",
            "Cans and lapt, Jedue dost prison, still thus? like a cept's last an \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t15kKVtGtNcj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9c1ee2b6-560a-42e9-f723-7129a98affc7"
      },
      "source": [
        "#Graph of Loss over t\r\n",
        "x = range(len(all_losses))\r\n",
        "plt.title(\"Loss over training of Vanilla RNN\")\r\n",
        "plt.scatter(x, all_losses)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f91c570a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTEbnmpyf3Bp"
      },
      "source": [
        "###Smapling with high temperature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtjy6NwsfynP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1a29af6-543e-4342-aef0-14ee1e114117"
      },
      "source": [
        "generate(decoder, prime_str=\"A\", temperature= 100, cuda=use_cuda)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A!\\r}4?qdaZkzp;ZNb$f#gG7\\nA]pZh\\tM0C.tKXY;\\t[\\x0bU%/ +1S)m6M\\x0bm8UEn\\t-cjC\"OL ]Q3S4v7h^MgjR,s=Lv%K0VHTCs\\n_kc0G9'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtCNwQTGf8zv"
      },
      "source": [
        "###Sampling with low temperature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtzpdEOXf78s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91c4d582-884d-45b6-af47-78cf92894aef"
      },
      "source": [
        "generate(decoder, prime_str=\"A\", temperature= 1, cuda=use_cuda)\r\n",
        "#Note the \\n is a new line"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"And that I'll I rensers fiolass world.\\n\\nBENVOLIO:\\nGo word in degrace,\\nNot come, up no dear\\nHer straig\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNV-XXd6T--i"
      },
      "source": [
        "###Samples generated for lowercase and uppercase alphabet for Vanilla RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "507IAylvT--j",
        "outputId": "5f6de083-827c-4f4e-ac0c-6413728d8bb6"
      },
      "source": [
        "for c in ascii_lowercase:\r\n",
        "  print(\"GENERATED SAMPLE FOR: \"+c)\r\n",
        "  print(generate(decoder, c, 100, cuda=use_cuda), '\\n')\r\n",
        "\r\n",
        "for c in ascii_uppercase:\r\n",
        "  print(\"GENERATED SAMPLE FOR: \"+c)\r\n",
        "  print(generate(decoder, c, 100, cuda=use_cuda), '\\n')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GENERATED SAMPLE FOR: a\n",
            "at.\n",
            "\n",
            "CAMILLO:\n",
            "Come\n",
            "A forgiverona to me 'band, my lord and tears,\n",
            "To makes am you are not ange to him  \n",
            "\n",
            "GENERATED SAMPLE FOR: b\n",
            "bere more art uneadenharn while of plantious majesty bearfue,\n",
            "He in borne you bears to me, and I thin \n",
            "\n",
            "GENERATED SAMPLE FOR: c\n",
            "compey.\n",
            "\n",
            "GREGORELHAS:\n",
            "Where hath brow, wherein the wine'st be deadly thee, my brother, my liege,\n",
            "And  \n",
            "\n",
            "GENERATED SAMPLE FOR: d\n",
            "d of ask and one but vilves,\n",
            "The tudgranted no, my foul on brout sooth to the world so sicken that wh \n",
            "\n",
            "GENERATED SAMPLE FOR: e\n",
            "e wrong must here's not men, it rims.\n",
            "\n",
            "CORIOLANUS:\n",
            "My man; good merry-reauty\n",
            "you make my brother's na \n",
            "\n",
            "GENERATED SAMPLE FOR: f\n",
            "fandity.\n",
            "\n",
            "MENENIUS:\n",
            "Now to hearts\n",
            "and her so? A duke, and thou hast, whose regot I have leave before  \n",
            "\n",
            "GENERATED SAMPLE FOR: g\n",
            "g?\n",
            "Ay,\n",
            "Speak out on home waking Marcius! less my dearly of Exgetuleets to power's chance it let that  \n",
            "\n",
            "GENERATED SAMPLE FOR: h\n",
            "here, but he now,\n",
            "The commands remain strong and fortune the dash them my liege; unfurs,\n",
            "For a dead d \n",
            "\n",
            "GENERATED SAMPLE FOR: i\n",
            "in the lords: my curse,\n",
            "And with my walls death!\n",
            "\n",
            "ESCALUS:\n",
            "I nouse, my lord, thou were shear make me, \n",
            "\n",
            "GENERATED SAMPLE FOR: j\n",
            "joy,\n",
            "But I woose heart, my eather tongue, that not to his larkern gates thee will be dead her be must \n",
            "\n",
            "GENERATED SAMPLE FOR: k\n",
            "k'\n",
            "Is eyes of this women with children?\n",
            "He with thee,\n",
            "Will the man for the old double me,\n",
            "My look'd w \n",
            "\n",
            "GENERATED SAMPLE FOR: l\n",
            "ll remureous to what I,\n",
            "With some fall old pardon.\n",
            "Kare mither. Come to the trample in the tribunes\n",
            "v \n",
            "\n",
            "GENERATED SAMPLE FOR: m\n",
            "movares by rage their hearts,\n",
            "Nor the cloudled once day be of makes to lose himself: you are\n",
            "No most  \n",
            "\n",
            "GENERATED SAMPLE FOR: n\n",
            "n's for therein speak farewell.\n",
            "\n",
            "BAPTISTA:\n",
            "Your looks this whip were his noble of compulied creasoner \n",
            "\n",
            "GENERATED SAMPLE FOR: o\n",
            "ost so, where is the white of all this never come to dischance my reonce and day be not top\n",
            "He must u \n",
            "\n",
            "GENERATED SAMPLE FOR: p\n",
            "pusing my houds the human:\n",
            "The lived, heaven no more of me a virchers? me and weally cheetre,\n",
            "And thi \n",
            "\n",
            "GENERATED SAMPLE FOR: q\n",
            "quor presence and speak of you I would a great as the revick'd thy envy bleedicged being me look the  \n",
            "\n",
            "GENERATED SAMPLE FOR: r\n",
            "r she\n",
            "The hand:\n",
            "From yourselve of your bore that fellows while.\n",
            "\n",
            "BRUTUS:\n",
            "Here you do you 'tis love as \n",
            "\n",
            "GENERATED SAMPLE FOR: s\n",
            "s bear these your action advised a tremperies.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I am a son so this grace-setwen.\n",
            "\n",
            "NOR \n",
            "\n",
            "GENERATED SAMPLE FOR: t\n",
            "thou birk my lips?\n",
            "\n",
            "LADY GREY:\n",
            "I have more's brother sequired unto these loathe is the orside to be n \n",
            "\n",
            "GENERATED SAMPLE FOR: u\n",
            "ur name good and even, like to Romession, I siments in your grands of the boded in old woman is not t \n",
            "\n",
            "GENERATED SAMPLE FOR: v\n",
            "ven a brow, stand of mine town my newles beggars to ordoh sons' grow or thee.\n",
            "If I contet of my quarr \n",
            "\n",
            "GENERATED SAMPLE FOR: w\n",
            "ward of my tribunes at his war vipt talk the keasust affected: of this black,\n",
            "Than\n",
            "proclaim of my swe \n",
            "\n",
            "GENERATED SAMPLE FOR: x\n",
            "xect thou, Cemb'd strike,\n",
            "No instant, and will show'd wherein succes such a gentleman and no fearship \n",
            "\n",
            "GENERATED SAMPLE FOR: y\n",
            "y mark or shad; and I'll could stand on\n",
            "And then in a thee\n",
            "He's pity Richal and way at wark you a gra \n",
            "\n",
            "GENERATED SAMPLE FOR: z\n",
            "zery cousin and bark to the father's sorrow, as 'twrantred the Duke and this my master and here,\n",
            "Fort \n",
            "\n",
            "GENERATED SAMPLE FOR: A\n",
            "And good looks prove to the days, from up where hasgest both from my cotupfine\n",
            "Thou art be my fever,  \n",
            "\n",
            "GENERATED SAMPLE FOR: B\n",
            "BRAUSBY:\n",
            "Besies' tears the like their eter the great know to accurse salised,\n",
            "I was on his grace; and \n",
            "\n",
            "GENERATED SAMPLE FOR: C\n",
            "CINLBAN OF:\n",
            "He not be are one undert again?\n",
            "There hand she would speak I love\n",
            "Whose voices to shall t \n",
            "\n",
            "GENERATED SAMPLE FOR: D\n",
            "Do Julieth marks the throne in that all the childly in much he marry, are not not will would were lov \n",
            "\n",
            "GENERATED SAMPLE FOR: E\n",
            "ES. Then I would broad the lift prince some misfarm\n",
            "I'll be are a man for in why, with a grest;\n",
            "which \n",
            "\n",
            "GENERATED SAMPLE FOR: F\n",
            "F RICHARD III:\n",
            "Nor nothing to me, royal; where shooking of my sail, the dayer\n",
            "That say looks of the h \n",
            "\n",
            "GENERATED SAMPLE FOR: G\n",
            "Giment!\n",
            "\n",
            "KING EDWARD IV:\n",
            "Nows ways\n",
            "The half come form\n",
            "Unto him are fond with thee for him breath ther \n",
            "\n",
            "GENERATED SAMPLE FOR: H\n",
            "He meet to forthyed while his put him, give their war she would Charles mernighted my face.\n",
            "\n",
            "PAULINA: \n",
            "\n",
            "GENERATED SAMPLE FOR: I\n",
            "I spent was armed and work,\n",
            "Which he would seement with the wonder to now, where I'll not this madam, \n",
            "\n",
            "GENERATED SAMPLE FOR: J\n",
            "JOs officer,\n",
            "Are before thy lifter wife all the world neithad? hall the king-day father, and ears, I' \n",
            "\n",
            "GENERATED SAMPLE FOR: K\n",
            "KING RICHARD III:\n",
            "Show strike,\n",
            "Shall you had be harms arand speech were her Bolour and makes, his sla \n",
            "\n",
            "GENERATED SAMPLE FOR: L\n",
            "Live,\n",
            "And here it indeed?\n",
            "\n",
            "GUNELIUS:\n",
            "Now I, sir.\n",
            "\n",
            "CAMILLO:\n",
            "How done, of a death by the daughter?\n",
            "\n",
            "GLO \n",
            "\n",
            "GENERATED SAMPLE FOR: M\n",
            "MMuch entertain.\n",
            "Hath after his daughter, king, and when, sir, as to me,\n",
            "And hast! contert of their f \n",
            "\n",
            "GENERATED SAMPLE FOR: N\n",
            "NCENTIO:\n",
            "What she say your wenter remedy, I am all Henry is perceen, welcome, and warn your mistress  \n",
            "\n",
            "GENERATED SAMPLE FOR: O\n",
            "ORD:\n",
            "They when thee as the murfueless wonder hand.\n",
            "And a man my wars his false wise, what we malim'd: \n",
            "\n",
            "GENERATED SAMPLE FOR: P\n",
            "PETIO:\n",
            "Been\n",
            "Return.\n",
            "\n",
            "GONZALO:\n",
            "A sear down.\n",
            "\n",
            "CLARENCE:\n",
            "Do in the curse to prespooch.\n",
            "\n",
            "ANGELO:\n",
            "Look.\n",
            "\n",
            "N \n",
            "\n",
            "GENERATED SAMPLE FOR: Q\n",
            "QVORDY CAPULET:\n",
            "There's prophed and he now, unto my house hand, that repirith to privated of hand, ha \n",
            "\n",
            "GENERATED SAMPLE FOR: R\n",
            "RULIUS:\n",
            "The humilius, my lord;\n",
            "Longing, will not promity with that he can I swear in his one tears: b \n",
            "\n",
            "GENERATED SAMPLE FOR: S\n",
            "SAwn confushio word a woes an hopher now clear\n",
            "To tears made thy dead consent, my lord.\n",
            "\n",
            "AUFIDIUS:\n",
            "Ar \n",
            "\n",
            "GENERATED SAMPLE FOR: T\n",
            "T:\n",
            "As my actords,\n",
            "He knee? who well and lengtholdst being heart at it. What is this wrong unto the fo \n",
            "\n",
            "GENERATED SAMPLE FOR: U\n",
            "UD:\n",
            "Then, benefition access a minish'd the book for the strike\n",
            "Have not wearer have in eyes brave it  \n",
            "\n",
            "GENERATED SAMPLE FOR: V\n",
            "VI:\n",
            "This my father: I came my looks; how calls to hour of my frief grace in God on my York's wrong to \n",
            "\n",
            "GENERATED SAMPLE FOR: W\n",
            "Whoke my wrong your hope of goded of thy hands, me. I do this book of us she enborten or bear my hand \n",
            "\n",
            "GENERATED SAMPLE FOR: X\n",
            "XERES:\n",
            "Sovereign 'em, who show more for the bitter, were want hare to disposed up-cordats. God near o \n",
            "\n",
            "GENERATED SAMPLE FOR: Y\n",
            "Y, more grace, the daughter tell the wife, and they are stand again and betting conseival will not sa \n",
            "\n",
            "GENERATED SAMPLE FOR: Z\n",
            "ZAnd the ring for my man,\n",
            "And though you must you degracious stood an lived.\n",
            "\n",
            "CAMILLO:\n",
            "Why whose eye  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDzKBnKVmruM"
      },
      "source": [
        "# #3 GRU RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJawX4To-NXi"
      },
      "source": [
        "###Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0K0ohFh-NXu"
      },
      "source": [
        "hidden_size = 100\r\n",
        "learning_rate = 0.01\r\n",
        "cell = \"gru\"\r\n",
        "n_layers = 2\r\n",
        "\r\n",
        "decoder = CharRNN(\r\n",
        "    n_characters,\r\n",
        "    hidden_size,\r\n",
        "    n_characters,\r\n",
        "    model=cell,\r\n",
        "    n_layers=n_layers,\r\n",
        ")\r\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "if use_cuda:\r\n",
        "    decoder.cuda()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOC2a71w-NXu"
      },
      "source": [
        "n_epochs = 2000\r\n",
        "chunk_len = 200\r\n",
        "print_every = 100\r\n",
        "batch_size = 100"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKhmwrQL-NXv"
      },
      "source": [
        "def train(inp, target):\r\n",
        "    hidden = decoder.init_hidden(batch_size)\r\n",
        "    if use_cuda:\r\n",
        "        hidden = hidden.cuda()\r\n",
        "    decoder.zero_grad()\r\n",
        "    loss = 0\r\n",
        "\r\n",
        "    for c in range(chunk_len):\r\n",
        "        output, hidden = decoder(inp[:,c], hidden)\r\n",
        "        loss += criterion(output.view(batch_size, -1), target[:,c])\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    decoder_optimizer.step()\r\n",
        "\r\n",
        "    #Old version (doesn't support zero indexing)\r\n",
        "    #return loss.data[0] / chunk_len\r\n",
        "    return loss.data / chunk_len"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl0ifPbj-W1N"
      },
      "source": [
        "###Train GRU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aUlT7UB-UCl",
        "outputId": "6de8ef47-9a79-4705-e106-66ce3bcb4bc7"
      },
      "source": [
        "start = time.time()\r\n",
        "all_losses = []\r\n",
        "loss_avg = 0\r\n",
        "\r\n",
        "print(\"Training for %d epochs...\" % n_epochs)\r\n",
        "for epoch in tqdm(range(1, n_epochs + 1)):\r\n",
        "    loss = train(*random_training_set(chunk_len, batch_size, data))\r\n",
        "    loss_avg += loss\r\n",
        "    all_losses.append(loss.item())\r\n",
        "    if epoch % print_every == 0:\r\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\r\n",
        "        print('loss: ', loss)\r\n",
        "        print(generate(decoder, 'Wh', 100, cuda=use_cuda), '\\n')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training for 2000 epochs...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [01:13<23:31,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1m 13s (100 5%) 1.7684]\n",
            "loss:  tensor(1.7684)\n",
            "Whe post:\n",
            "Or afceagay for the truck to good yor him to therefore I hands cany your stell and with tere \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 200/2000 [02:26<22:04,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2m 26s (200 10%) 1.5859]\n",
            "loss:  tensor(1.5859)\n",
            "Wherer, and last thine\n",
            "A the worls of him, and in then came eyes of bosily\n",
            "They and plaintent three.\n",
            "\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 300/2000 [03:39<20:49,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3m 39s (300 15%) 1.5212]\n",
            "loss:  tensor(1.5212)\n",
            "Where beriend seeter.\n",
            "\n",
            "PETRUCHIO:\n",
            "I cunsel'd the blood ours' two no time.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "O dempting \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 400/2000 [04:51<19:53,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4m 51s (400 20%) 1.4770]\n",
            "loss:  tensor(1.4770)\n",
            "Whus your hand, time of prayers with he's a right\n",
            "As lords, no all, my noble habfins?\n",
            "\n",
            "All:\n",
            "How please \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 500/2000 [06:03<18:28,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[6m 3s (500 25%) 1.4501]\n",
            "loss:  tensor(1.4501)\n",
            "Whemen hold with him to had us:\n",
            "Come them too mean are the prince, but the sorrow?\n",
            "What so me leave up \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 600/2000 [07:15<16:58,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7m 15s (600 30%) 1.4219]\n",
            "loss:  tensor(1.4219)\n",
            "Wheast thou art common me him\n",
            "Shall breathe and lords contend to deques back?\n",
            "\n",
            "LADY ANNE:\n",
            "But for I st \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 700/2000 [08:27<15:59,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[8m 27s (700 35%) 1.4081]\n",
            "loss:  tensor(1.4081)\n",
            "Whis merry then suster of you,\n",
            "Thou sings their country to heaves, dark wail the crown\n",
            "Is supprily hat \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 800/2000 [09:38<14:33,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9m 38s (800 40%) 1.4216]\n",
            "loss:  tensor(1.4216)\n",
            "Wherefled under it. He have should York;\n",
            "And to the rest stirry of villain,\n",
            "And begin it false. Well,  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 900/2000 [10:49<13:15,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10m 49s (900 45%) 1.3827]\n",
            "loss:  tensor(1.3827)\n",
            "Whomally said a said leave?\n",
            "\n",
            "ESCALUS:\n",
            "Why, he cannot I know the bawd.\n",
            "\n",
            "HORTENSIO:\n",
            "Sir, begreil to merc \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1000/2000 [12:01<11:57,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12m 0s (1000 50%) 1.3741]\n",
            "loss:  tensor(1.3741)\n",
            "Wher, that I lord, that I cannot can love;\n",
            "And grings are themselves, with me, badly be half.\n",
            "\n",
            "QUEEN:\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1100/2000 [13:12<10:51,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[13m 12s (1100 55%) 1.3711]\n",
            "loss:  tensor(1.3711)\n",
            "Why, sir, and Lord Hasting and beggar.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You have foull so our field?\n",
            "\n",
            "KING RICHARD III \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1200/2000 [14:23<09:34,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14m 23s (1200 60%) 1.3675]\n",
            "loss:  tensor(1.3675)\n",
            "Whee this,? Woud,\n",
            "My ground and trudge a Buckingham, go him, though poor I lits.\n",
            "\n",
            "ROMEO:\n",
            "And I, are yo \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1300/2000 [15:34<08:28,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15m 34s (1300 65%) 1.3915]\n",
            "loss:  tensor(1.3915)\n",
            "Whee my master's land, ado?\n",
            "\n",
            "MERCUTIO:\n",
            "Come men my disgreak above my good stoo\n",
            "at hand of shall serve  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1400/2000 [16:45<07:18,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[16m 45s (1400 70%) 1.3810]\n",
            "loss:  tensor(1.3810)\n",
            "Whom confesses the deep of heart?\n",
            "\n",
            "First I have:\n",
            "For bitter than your night with his worn I be no more \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1500/2000 [17:56<05:58,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[17m 56s (1500 75%) 1.3739]\n",
            "loss:  tensor(1.3739)\n",
            "What's have been?\n",
            "\n",
            "AUFIDIUS:\n",
            "I do the satisf.\n",
            "\n",
            "ANGELO:\n",
            "A blows out stay at me to this goodling.\n",
            "Now ba \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1600/2000 [19:07<04:50,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[19m 7s (1600 80%) 1.3738]\n",
            "loss:  tensor(1.3738)\n",
            "What curst his parted but in common shall be\n",
            "signity on the friend. Let their will fall morribut\n",
            "I say \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1700/2000 [20:18<03:34,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[20m 18s (1700 85%) 1.3849]\n",
            "loss:  tensor(1.3849)\n",
            "What much invoterable study?\n",
            "\n",
            "OXFORD:\n",
            "These uncle hier days of me, I do pray thee;\n",
            "Yet me.\n",
            "\n",
            "GREMIO:\n",
            "I  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 1800/2000 [21:28<02:30,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21m 28s (1800 90%) 1.3596]\n",
            "loss:  tensor(1.3596)\n",
            "Which they they comes the view,\n",
            "If thou art to certain of sufferess twenty taper-\n",
            "Of to those night in \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1900/2000 [22:37<01:09,  1.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[22m 37s (1900 95%) 1.3768]\n",
            "loss:  tensor(1.3768)\n",
            "Which so stain'd to the adprines:\n",
            "I enjoin'd.\n",
            "\n",
            "Clown:\n",
            "You have the as at a treasons unfortune;\n",
            "Thou wi \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [23:47<00:00,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23m 47s (2000 100%) 1.3388]\n",
            "loss:  tensor(1.3388)\n",
            "When storm'd him he's cup of ever\n",
            "That he done by his folery is,\n",
            "What left what thou that thought may  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "8eBqK64t-bhU",
        "outputId": "00420a7e-58dd-4ba5-948d-8d18308864d1"
      },
      "source": [
        "#Graph of Loss over t\r\n",
        "x = range(len(all_losses))\r\n",
        "plt.title(\"Loss over training of GRU\")\r\n",
        "plt.scatter(x, all_losses)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f91c50d9b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jazoYpoMT6nq"
      },
      "source": [
        "###Samples generated for lowercase and uppercase alphabet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F49sEXQlT6nz",
        "outputId": "4945fb29-6c1d-4436-b463-22655efc8ee7"
      },
      "source": [
        "for c in ascii_lowercase:\r\n",
        "  print(\"GENERATED SAMPLE FOR: \"+c)\r\n",
        "  print(generate(decoder, c, 100, cuda=use_cuda), '\\n')\r\n",
        "\r\n",
        "for c in ascii_uppercase:\r\n",
        "  print(\"GENERATED SAMPLE FOR: \"+c)\r\n",
        "  print(generate(decoder, c, 100, cuda=use_cuda), '\\n')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GENERATED SAMPLE FOR: a\n",
            "ard and speak.\n",
            "\n",
            "Lord MOTwithinss and be stain,\n",
            "Looket the great cousin with thy goodly town;\n",
            "Why, the \n",
            "\n",
            "GENERATED SAMPLE FOR: b\n",
            "bling, nor their head thee:\n",
            "The dading more nothing of poor, and shall be sign of\n",
            "Of this days and sh \n",
            "\n",
            "GENERATED SAMPLE FOR: c\n",
            "cries to the calms,\n",
            "Which we'll be beak the way, being homely\n",
            "At the good will not his common'd to th \n",
            "\n",
            "GENERATED SAMPLE FOR: d\n",
            "d where that thy wife.\n",
            "\n",
            "HORTENSIO:\n",
            "And let the honour is your horse?\n",
            "Tell thee, and dissomention's bl \n",
            "\n",
            "GENERATED SAMPLE FOR: e\n",
            "e I did be beak, for her kindly\n",
            "As an own stirrance would was to the varlet\n",
            "Upon, in thine old in the \n",
            "\n",
            "GENERATED SAMPLE FOR: f\n",
            "fector, it streets are begn\n",
            "To prove your head so devised.\n",
            "He am I am turn'd, with the good Laurence, \n",
            "\n",
            "GENERATED SAMPLE FOR: g\n",
            "g kindrate thee thy vile.\n",
            "\n",
            "HASTINGS:\n",
            "Thy sumber the death should be a led before when there\n",
            "Or now la \n",
            "\n",
            "GENERATED SAMPLE FOR: h\n",
            "hy like prince, whence of his for.\n",
            "\n",
            "WARWICK:\n",
            "Commish, along, Lewis with him!\n",
            "\n",
            "MIRANDA:\n",
            "I do he is not \n",
            "\n",
            "GENERATED SAMPLE FOR: i\n",
            "ista like nighment\n",
            "Have three virtuous lords and accuse your cousin.\n",
            "\n",
            "AUTOLYCUS:\n",
            "What! How more?\n",
            "\n",
            "ARC \n",
            "\n",
            "GENERATED SAMPLE FOR: j\n",
            "joy's cursed friends and to told\n",
            "conselless discrope the days--from shall be joy,\n",
            "And thing of the li \n",
            "\n",
            "GENERATED SAMPLE FOR: k\n",
            "k and gone!\n",
            "\n",
            "LADY WARD:\n",
            "Ay, all thy virges, in the worst, that is and the queen.\n",
            "\n",
            "TRANIO:\n",
            "The points  \n",
            "\n",
            "GENERATED SAMPLE FOR: l\n",
            "l that state, how the standing not\n",
            "And straggers, therefore a pardon, to shelm, sir,\n",
            "A kiss our preci \n",
            "\n",
            "GENERATED SAMPLE FOR: m\n",
            "my gracious good cut,\n",
            "That voices his stay means and all my fingers:\n",
            "If ever he hateful time, sir, he \n",
            "\n",
            "GENERATED SAMPLE FOR: n\n",
            "ns.\n",
            "\n",
            "GLOUCESTER:\n",
            "It for your land secret again to be gone;\n",
            "But that I am shepherd's king.\n",
            "\n",
            "CORIOLANUS \n",
            "\n",
            "GENERATED SAMPLE FOR: o\n",
            "or?\n",
            "\n",
            "POLIXENES:\n",
            "More Annting, that Edward's bodies,\n",
            "I of mes do upon the lips with winds;\n",
            "And they ar \n",
            "\n",
            "GENERATED SAMPLE FOR: p\n",
            "par; you of voices.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "We was that scape for the cause on thy tegnlect\n",
            "The wife of thr \n",
            "\n",
            "GENERATED SAMPLE FOR: q\n",
            "queend the\n",
            "better bid my past away. The rage thee at his best\n",
            "alle that we are the town that your bra \n",
            "\n",
            "GENERATED SAMPLE FOR: r\n",
            "rage, for his persons.\n",
            "\n",
            "AUTOLYCUS:\n",
            "For, that he were less to the send to thee that stand?\n",
            "\n",
            "KING EDWAR \n",
            "\n",
            "GENERATED SAMPLE FOR: s\n",
            "s\n",
            "And bred upon thee from your words,\n",
            "And beseech the great what's makes it: that that bow and when s \n",
            "\n",
            "GENERATED SAMPLE FOR: t\n",
            "tanced the night.\n",
            "\n",
            "RIVERS:\n",
            "Knock thou art give you say yours are or a breedic\n",
            "And therefore deedless' \n",
            "\n",
            "GENERATED SAMPLE FOR: u\n",
            "u to my friends to,\n",
            "Behold, look Somersemial, we are to\n",
            "thee, sir. I shall ground.\n",
            "\n",
            "MARCIUS:\n",
            "Happy sa \n",
            "\n",
            "GENERATED SAMPLE FOR: v\n",
            "ve the hardly hang for a\n",
            "man and the news shall speeding that are fly\n",
            "Approachers, any to with the we \n",
            "\n",
            "GENERATED SAMPLE FOR: w\n",
            "wound to die hath way with closest.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Fell your head, I am content, for why, Thomas Sa \n",
            "\n",
            "GENERATED SAMPLE FOR: x\n",
            "xemio, and to take and love!\n",
            "Who hast the law your engreet endalty?\n",
            "\n",
            "WARWICK:\n",
            "Though thou march to do \n",
            "\n",
            "GENERATED SAMPLE FOR: y\n",
            "y.\n",
            "\n",
            "POLIXENES:\n",
            "How suhpicions? service, as another years,\n",
            "That which a gracious bride\n",
            "The man of him  \n",
            "\n",
            "GENERATED SAMPLE FOR: z\n",
            "zen the leavest of the great\n",
            "Of which thought of it to my person?\n",
            "\n",
            "POLIXENES:\n",
            "He knows and weeds;\n",
            "Who \n",
            "\n",
            "GENERATED SAMPLE FOR: A\n",
            "AND:\n",
            "My lord; but a master, thy chord, and will she were go\n",
            "As hadst thou in ancient name sufferuch,\n",
            " \n",
            "\n",
            "GENERATED SAMPLE FOR: B\n",
            "But will not our birth,\n",
            "A five of the depose to our father:\n",
            "And to be more brief, no, our will we wer \n",
            "\n",
            "GENERATED SAMPLE FOR: C\n",
            "CHIO:\n",
            "No things, should go with thee word,\n",
            "And like am I prosemity;\n",
            "His kings to himself as I did lov \n",
            "\n",
            "GENERATED SAMPLE FOR: D\n",
            "Diss to thy daughter:\n",
            "But if I, my words, tell liven'd come;\n",
            "For then hath struck shall weary.\n",
            "\n",
            "GREMI \n",
            "\n",
            "GENERATED SAMPLE FOR: E\n",
            "Eg niterment: ment to play, your tribunes,\n",
            "And no dares our servant: 'twere all you born.\n",
            "\n",
            "Lord Marsh \n",
            "\n",
            "GENERATED SAMPLE FOR: F\n",
            "First Lord:\n",
            "If you may spirit of the sea at his cold and one and have\n",
            "That down again. What had all t \n",
            "\n",
            "GENERATED SAMPLE FOR: G\n",
            "GADY A:\n",
            "Ay, with will in thy son, blows of say throw to rust.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Quick distracty, first \n",
            "\n",
            "GENERATED SAMPLE FOR: H\n",
            "HENRY VI:\n",
            "Nort and an look him be succession:\n",
            "And thou dost to this plot,--\n",
            "\n",
            "MENENIUS:\n",
            "Not gone! who  \n",
            "\n",
            "GENERATED SAMPLE FOR: I\n",
            "IO:\n",
            "I pray, at a gabled from thy sweet\n",
            "With might the day to perfalty, will be keep to prove the\n",
            "fart \n",
            "\n",
            "GENERATED SAMPLE FOR: J\n",
            "JULIET:\n",
            "He's fair still us with the Montague.\n",
            "\n",
            "LADY ANNE:\n",
            "O, regard, I was his brow.\n",
            "\n",
            "CLARENCE:\n",
            "To my \n",
            "\n",
            "GENERATED SAMPLE FOR: K\n",
            "KE O:\n",
            "Give me thou wilt so Bolingbroke. But Henry fills by with\n",
            "the pastage worthine:\n",
            "The most ouden  \n",
            "\n",
            "GENERATED SAMPLE FOR: L\n",
            "LAUS:\n",
            "Now! What come in my kings great empleso?\n",
            "\n",
            "ANGELO:\n",
            "Why, they have sense not the father, the bre \n",
            "\n",
            "GENERATED SAMPLE FOR: M\n",
            "Monce to-morrow. Provost\n",
            "That we were to the rackness to be soldiers;\n",
            "There leave upon your bastard's \n",
            "\n",
            "GENERATED SAMPLE FOR: N\n",
            "No Mercutio, will see them.\n",
            "Look, that we have came to him possible!\n",
            "\n",
            "HORTENSIO:\n",
            "I' the king, though  \n",
            "\n",
            "GENERATED SAMPLE FOR: O\n",
            "OO:\n",
            "Why struck forbless Very well content,\n",
            "Bidow him and strail thy happy brideth the worsed,\n",
            "Sin sol \n",
            "\n",
            "GENERATED SAMPLE FOR: P\n",
            "PULET:\n",
            "Not the will be picking the steadless are\n",
            "Friard the worn to policy.'\n",
            "\n",
            "WARWICK:\n",
            "And before be  \n",
            "\n",
            "GENERATED SAMPLE FOR: Q\n",
            "QUEEN ELIZABETH:\n",
            "What distress your conscantly and by our Capulisted by\n",
            "Betwixt thy braces of this wi \n",
            "\n",
            "GENERATED SAMPLE FOR: R\n",
            "RICHARD:\n",
            "Now, let it is like and my life thereby by\n",
            "me both himself to the bred Vophail weeds,\n",
            "That h \n",
            "\n",
            "GENERATED SAMPLE FOR: S\n",
            "Swerid him.\n",
            "\n",
            "CORIOLANUS:\n",
            "O, to you, I is't the\n",
            "the two my fortuning in and my father,\n",
            "As by full of t \n",
            "\n",
            "GENERATED SAMPLE FOR: T\n",
            "To friends fool's manisted mother's bed?\n",
            "\n",
            "MENENIUS:\n",
            "And side, have thereors! the princting upon the e \n",
            "\n",
            "GENERATED SAMPLE FOR: U\n",
            "US:\n",
            "There would like my sword, that is to him, let my bawd,\n",
            "And thou hast all their brother pray nigh \n",
            "\n",
            "GENERATED SAMPLE FOR: V\n",
            "VI:\n",
            "I'll tell hither and thee of your foul was\n",
            "And have well in war to infect him Jupit,\n",
            "She would a  \n",
            "\n",
            "GENERATED SAMPLE FOR: W\n",
            "What.\n",
            "\n",
            "MENENIUS:\n",
            "They have plot it ladies; and could be, to the forgot and rather.\n",
            "\n",
            "AUTOLYBUNTENS:\n",
            "Ye \n",
            "\n",
            "GENERATED SAMPLE FOR: X\n",
            "XELIEL:\n",
            "Now, let it not thing to this nature.\n",
            "\n",
            "CORIOLANUS:\n",
            "God be not town, for bite thy best\n",
            "Importl \n",
            "\n",
            "GENERATED SAMPLE FOR: Y\n",
            "YR:\n",
            "It find the duke with your house. And fornid and mercy.\n",
            "\n",
            "JOHN OF GAUNT:\n",
            "The tribunes to the noble \n",
            "\n",
            "GENERATED SAMPLE FOR: Z\n",
            "ZUBELET:\n",
            "Your her woo's have one that art Elbow the tries.\n",
            "I have for the sunded of the traitor; we a \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCh0qpMEzo1m"
      },
      "source": [
        "# #3.5 Comparision between Vanilla RNN and GRU RNN on Shakespeare Dataset\r\n",
        "- Loss was lower for the GRU (~1.3 for GRU vs. ~1.4 for RNN)\r\n",
        "- In my opinon, the samples generated by the GRU were better than the ones generated by the Vanilla RNN. The GRU samples seemed to have a better usage of punctuation, capital vs. lower case letters and realistic word length. Also, I personally thought the GRU had somewhat better grammar than the vanilla RNN (even though some of the words were made up)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxh3T_QDmuka"
      },
      "source": [
        "# #4 King James Bible Training GRU RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2VMnbufmtmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415b0973-3e8d-4aa5-d790-7ea5c2db9418"
      },
      "source": [
        "target_url = \"https://raw.githubusercontent.com/ErikSchierboom/sentencegenerator/master/samples/the-king-james-bible.txt\"\r\n",
        "data = DownloadFile(target_url)\r\n",
        "#print(random_training_set(10, 8, data))\r\n",
        "print(data[10:100])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Book of Moses:  Called Genesis\n",
            "\n",
            "\n",
            "1:1 In the beginning God created the heaven and the eart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBjMa6hnYLwu"
      },
      "source": [
        "###Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE6wLlihYLwx"
      },
      "source": [
        "hidden_size = 100\r\n",
        "learning_rate = 0.01\r\n",
        "cell = \"gru\"\r\n",
        "n_layers = 2\r\n",
        "\r\n",
        "decoder = CharRNN(\r\n",
        "    n_characters,\r\n",
        "    hidden_size,\r\n",
        "    n_characters,\r\n",
        "    model=cell,\r\n",
        "    n_layers=n_layers,\r\n",
        ")\r\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "if use_cuda:\r\n",
        "    decoder.cuda()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mly7PR9MYLwy"
      },
      "source": [
        "n_epochs = 2000\r\n",
        "chunk_len = 200\r\n",
        "print_every = 100\r\n",
        "batch_size = 100"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e-NBienYLwy"
      },
      "source": [
        "def train(inp, target):\r\n",
        "    hidden = decoder.init_hidden(batch_size)\r\n",
        "    if use_cuda:\r\n",
        "        hidden = hidden.cuda()\r\n",
        "    decoder.zero_grad()\r\n",
        "    loss = 0\r\n",
        "\r\n",
        "    for c in range(chunk_len):\r\n",
        "        output, hidden = decoder(inp[:,c], hidden)\r\n",
        "        loss += criterion(output.view(batch_size, -1), target[:,c])\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    decoder_optimizer.step()\r\n",
        "\r\n",
        "    #Old version (doesn't support zero indexing)\r\n",
        "    #return loss.data[0] / chunk_len\r\n",
        "    return loss.data / chunk_len"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRdyKJFvYQjx"
      },
      "source": [
        "###Train GRU with King Jame's Bible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5tgNG0fOB0u",
        "outputId": "d978b5a8-aeb8-4616-da52-780b1f5d1177"
      },
      "source": [
        "#TRAIN GRU with King James Bible:\r\n",
        "start = time.time()\r\n",
        "all_losses = []\r\n",
        "loss_avg = 0\r\n",
        "\r\n",
        "print(\"Training for %d epochs...\" % n_epochs)\r\n",
        "for epoch in tqdm(range(1, n_epochs + 1)):\r\n",
        "    loss = train(*random_training_set(chunk_len, batch_size, data))\r\n",
        "    loss_avg += loss\r\n",
        "    all_losses.append(loss.item())\r\n",
        "    if epoch % print_every == 0:\r\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\r\n",
        "        print('loss: ', loss)\r\n",
        "        print(generate(decoder, 'Wh', 100, cuda=use_cuda), '\\n')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training for 2000 epochs...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [01:11<22:53,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1m 11s (100 5%) 1.5699]\n",
            "loss:  tensor(1.5699)\n",
            "Whied a tought\n",
            "fup.\n",
            "\n",
            "28:33 And Jerusarose, let of Dave they unto the gon, which hath of\n",
            "bring the song \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 200/2000 [02:22<22:13,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2m 22s (200 10%) 1.3697]\n",
            "loss:  tensor(1.3697)\n",
            "Wherefore the earth, he were to Habashals, and debleining the\n",
            "land, people to breaven; but thy days sh \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 300/2000 [03:32<20:33,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[3m 32s (300 15%) 1.2704]\n",
            "loss:  tensor(1.2704)\n",
            "Whose it, and their saw the\n",
            "combe as it her and the world also were fall of into the land shall be a s \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 400/2000 [04:42<19:00,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4m 42s (400 20%) 1.2399]\n",
            "loss:  tensor(1.2399)\n",
            "Whempind that I made the morning and debitants.\n",
            "\n",
            "19:12 And it, and valluath, let us in the cattle with \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 500/2000 [05:54<18:29,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[5m 54s (500 25%) 1.2635]\n",
            "loss:  tensor(1.2635)\n",
            "Whatsoever in the lamed up\n",
            "year of every preceive, who stoned, bring the well shall be a\n",
            "seventh that  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 600/2000 [07:05<16:58,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7m 5s (600 30%) 1.2205]\n",
            "loss:  tensor(1.2205)\n",
            "Wheebered be one of the\n",
            "nead.\n",
            "\n",
            "19:25 The sons of Israel shall be a man that with all the\n",
            "land of Shemo \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 700/2000 [08:16<15:27,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[8m 16s (700 35%) 1.2154]\n",
            "loss:  tensor(1.2154)\n",
            "Wheel said unto her, As that the LORD shall discord unto all they gospel.\n",
            "\n",
            "9:10 When he been the earth \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 800/2000 [09:26<14:10,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9m 26s (800 40%) 1.1671]\n",
            "loss:  tensor(1.1671)\n",
            "What themselves of the LORD a visite him.\n",
            "\n",
            "33:15 And Joseph much man locks, and ye shall I lifes spake \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 900/2000 [10:35<13:02,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10m 35s (900 45%) 1.1811]\n",
            "loss:  tensor(1.1811)\n",
            "Whose answered with\n",
            "the LORD of Moses, there shete ears, therefore the destroy these day of thy days.\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1000/2000 [11:45<11:52,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[11m 45s (1000 50%) 1.1699]\n",
            "loss:  tensor(1.1699)\n",
            "When they been the\n",
            "son of Anth he shall be of the delivered bread.\n",
            "\n",
            "33:4 For they shall commanded us w \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1100/2000 [12:54<10:33,  1.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12m 54s (1100 55%) 1.1609]\n",
            "loss:  tensor(1.1609)\n",
            "When all the light of the\n",
            "drink: and he righteous left some of his hills.\n",
            "\n",
            "3:9 And thou hast not sat m \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1200/2000 [14:03<09:25,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[14m 3s (1200 60%) 1.1859]\n",
            "loss:  tensor(1.1859)\n",
            "Whemen\n",
            "the world whom then will build me accovertward by the day shall\n",
            "but not him, appeared the fools \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1300/2000 [15:12<08:26,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[15m 12s (1300 65%) 1.1513]\n",
            "loss:  tensor(1.1513)\n",
            "Whithe generation shall be learn\n",
            "entering: and they ship shall slad imson that was with him read\n",
            "the e \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1400/2000 [16:21<06:53,  1.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[16m 21s (1400 70%) 1.1325]\n",
            "loss:  tensor(1.1325)\n",
            "What the nation of the sword, and which is not his cities of said unto the hand of the LORD, and he la \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1500/2000 [17:29<05:44,  1.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[17m 29s (1500 75%) 1.1776]\n",
            "loss:  tensor(1.1776)\n",
            "Whengeloch the Father, and took a country on the old spirit.\n",
            "\n",
            "2:25 For they place the God of God, and  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1600/2000 [18:38<04:37,  1.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[18m 38s (1600 80%) 1.1451]\n",
            "loss:  tensor(1.1451)\n",
            "Where into the way\n",
            "appointified the name of the LORD.\n",
            "\n",
            "21:21 For the LORD said, A waters of the LORD f \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1700/2000 [19:47<03:30,  1.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[19m 47s (1700 85%) 1.1316]\n",
            "loss:  tensor(1.1316)\n",
            "What thou it shall be stames, even it in one fear our clees with the bancher,\n",
            "and prayer of Michan, an \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 1800/2000 [20:55<02:18,  1.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[20m 55s (1800 90%) 1.1607]\n",
            "loss:  tensor(1.1607)\n",
            "When the same voice, and fifty thousand\n",
            "out of the fourth wicked of hosts, and said, Cherily and his d \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1900/2000 [22:04<01:09,  1.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[22m 4s (1900 95%) 1.1250]\n",
            "loss:  tensor(1.1250)\n",
            "When they shall the prophet, the Pershech hath\n",
            "heard all the wilderness accordities, and all there and \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [23:12<00:00,  1.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23m 12s (2000 100%) 1.1412]\n",
            "loss:  tensor(1.1412)\n",
            "Which to thy disciples' father's heaven and\n",
            "thy sick, and I am ready are perish. And Elihman took upon \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "7nEVhB_QPW6a",
        "outputId": "5b6595a0-ece6-4c08-b119-8d3864f93df0"
      },
      "source": [
        "#Graph of Loss over t\r\n",
        "x = range(len(all_losses))\r\n",
        "plt.title(\"Loss over training of GRU for King James Bible\")\r\n",
        "plt.scatter(x, all_losses)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f91c4fd1c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA0pmen4Ssc2"
      },
      "source": [
        "###Samples generated for lowercase and uppercase alphabet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtCYQJEaRohx",
        "outputId": "29a98b04-2cf8-4490-dbf0-c1e194e10daa"
      },
      "source": [
        "for c in ascii_lowercase:\r\n",
        "  print(\"GENERATED SAMPLE FOR: \"+c)\r\n",
        "  print(generate(decoder, c, 100, cuda=use_cuda), '\\n')\r\n",
        "\r\n",
        "for c in ascii_uppercase:\r\n",
        "  print(\"GENERATED SAMPLE FOR: \"+c)\r\n",
        "  print(generate(decoder, c, 100, cuda=use_cuda), '\\n')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GENERATED SAMPLE FOR: a\n",
            "and of Jacob also\n",
            "shall be on the man year, that the LORD took the overlai reigned of\n",
            "silent for the  \n",
            "\n",
            "GENERATED SAMPLE FOR: b\n",
            "be to the\n",
            "waters of Zebulun.\n",
            "\n",
            "5:1 The soul of the tabernacle of the dead and unto them by his salvati \n",
            "\n",
            "GENERATED SAMPLE FOR: c\n",
            "carketh thee, and not the sons of Amorecomay: 7:5 And\n",
            "Simeon the trespass shall be men of the Levites \n",
            "\n",
            "GENERATED SAMPLE FOR: d\n",
            "d a children came, and we be reachelour, and kill\n",
            "the heart: and she went away, neither that sacrific \n",
            "\n",
            "GENERATED SAMPLE FOR: e\n",
            "ed, and purple of the fourhelks, and believed in\n",
            "him.\n",
            "\n",
            "51:40 If the heave of the wisdom of the walls  \n",
            "\n",
            "GENERATED SAMPLE FOR: f\n",
            "f the end\n",
            "of the enemy of the man in the flesh, neither were not fintest\n",
            "to the secret of the flesh;  \n",
            "\n",
            "GENERATED SAMPLE FOR: g\n",
            "goeased age unto the other redeepron.\n",
            "\n",
            "39:1 Therefore which much may be as from God, nor men of hosts \n",
            "\n",
            "GENERATED SAMPLE FOR: h\n",
            "hey against the breakest them, and in the same\n",
            "will let thee your lord Jeremiah the house; but they w \n",
            "\n",
            "GENERATED SAMPLE FOR: i\n",
            "ination: and thou hast\n",
            "long shall they laid and have numbracle of God were none charged out\n",
            "of the st \n",
            "\n",
            "GENERATED SAMPLE FOR: j\n",
            "jah anger and the eals, if I hath\n",
            "bloodeth about was made to the days of a prophets unto me.\n",
            "\n",
            "12:7 Th \n",
            "\n",
            "GENERATED SAMPLE FOR: k\n",
            "ke of thy people\n",
            "old.\n",
            "\n",
            "24:16 Now the land of Esaknes that are saints, what thou hath\n",
            "you away unto th \n",
            "\n",
            "GENERATED SAMPLE FOR: l\n",
            "ld with all the watch of the land of Egypt: and the fephturch made by\n",
            "the commandparteth observes is  \n",
            "\n",
            "GENERATED SAMPLE FOR: m\n",
            "m the sons of Assyria which were were not he for thy supplications:) and they place it,\n",
            "and which I s \n",
            "\n",
            "GENERATED SAMPLE FOR: n\n",
            "nd lay the people about the earth of God, then I will take not to\n",
            "the wall of Judah, and hand deliver \n",
            "\n",
            "GENERATED SAMPLE FOR: o\n",
            "of the land of Judah's son said unto Nethael, Where he had\n",
            "bless the well, and of the inhabitants of  \n",
            "\n",
            "GENERATED SAMPLE FOR: p\n",
            "p thou didst thou shaken of the ephod to his land, and so that they know that for\n",
            "me, seel thou were  \n",
            "\n",
            "GENERATED SAMPLE FOR: q\n",
            "quak of the water of the LORD death\n",
            "in a wall go, that his harps, where they had know that I will kep \n",
            "\n",
            "GENERATED SAMPLE FOR: r\n",
            "r\n",
            "Eliel, and Abimahad, and my seed: and the men of Israel had set nought\n",
            "returned away from the capta \n",
            "\n",
            "GENERATED SAMPLE FOR: s\n",
            "s, or fled to go, that I will he spake to\n",
            "desolate and his heart, and brought the men of Israel.\n",
            "\n",
            "15: \n",
            "\n",
            "GENERATED SAMPLE FOR: t\n",
            "the LORD\n",
            "may be written to the Levites that passeth before thee.\n",
            "\n",
            "7:19 And they were sauth them; and  \n",
            "\n",
            "GENERATED SAMPLE FOR: u\n",
            "urst with the flock, and the most were quieted; and his wives be\n",
            "the four had probens upon a eat a fl \n",
            "\n",
            "GENERATED SAMPLE FOR: v\n",
            "ver will not mine enemies, and\n",
            "shewed were these an in the midst of the earth them.\n",
            "\n",
            "25:12 And the pa \n",
            "\n",
            "GENERATED SAMPLE FOR: w\n",
            "which may be so every man unto the other one going\n",
            "of the light of Pethite; I will bring the fourth m \n",
            "\n",
            "GENERATED SAMPLE FOR: x\n",
            "x callow it\n",
            "war their words and their families and his dead, that every\n",
            "clothes, which the LORD shall \n",
            "\n",
            "GENERATED SAMPLE FOR: y\n",
            "y and the way of the two hour they\n",
            "neighbour day, and thou shalt not be a fire?  20:4 And his mine ea \n",
            "\n",
            "GENERATED SAMPLE FOR: z\n",
            "z of the Jesus and said, she sent up commother and twenty year of\n",
            "these that were to come to pass, an \n",
            "\n",
            "GENERATED SAMPLE FOR: A\n",
            "And Jehosel, saying, Lo, I will he saw them by the\n",
            "same thee this friend, every cities which is blowa \n",
            "\n",
            "GENERATED SAMPLE FOR: B\n",
            "But was the\n",
            "chambers unto the golden in one veid, and the litten of the LORD\n",
            "shall be for doked, and  \n",
            "\n",
            "GENERATED SAMPLE FOR: C\n",
            "Comple and opened your daughters of the bondage, and to\n",
            "weary our name.\n",
            "\n",
            "119:4 Thou centurion shall b \n",
            "\n",
            "GENERATED SAMPLE FOR: D\n",
            "D for the land the law: and he said unto them, This is the elder blessed him,\n",
            "the spirit themselves d \n",
            "\n",
            "GENERATED SAMPLE FOR: E\n",
            "Ephesuren of Israel.\n",
            "\n",
            "103:13 Then Searon and Israel had numbered and go into the\n",
            "people undersmained  \n",
            "\n",
            "GENERATED SAMPLE FOR: F\n",
            "For my name, came not unto the watless of God will gathered her uncleanness, as yet when the sinner w \n",
            "\n",
            "GENERATED SAMPLE FOR: G\n",
            "God with great scripub, and which will I offered.\n",
            "\n",
            "8:10 I will be weep with Abram and Abraham, that t \n",
            "\n",
            "GENERATED SAMPLE FOR: H\n",
            "Hamaria the son of Assyria, the son of Zeriophiel, saith the LORD,\n",
            "and yet should been heard the peac \n",
            "\n",
            "GENERATED SAMPLE FOR: I\n",
            "I was come to peace, and will I cut by the\n",
            "hedge concerning up to walk of the country of the hand of  \n",
            "\n",
            "GENERATED SAMPLE FOR: J\n",
            "Jeariasee unto the wat of them? Israel your face of\n",
            "the mountains about; but he shall be after, the k \n",
            "\n",
            "GENERATED SAMPLE FOR: K\n",
            "Kaanite is in the temple of Israel among you,\n",
            "and come counselven as a good the wildeons'.\n",
            "\n",
            "1:11 And  \n",
            "\n",
            "GENERATED SAMPLE FOR: L\n",
            "LORD toward the word of the LORD, the fourth had\n",
            "faith unto thy day.\n",
            "\n",
            "4:16 All thou shalt not shew th \n",
            "\n",
            "GENERATED SAMPLE FOR: M\n",
            "Magned the book of\n",
            "the inhabitants, and that she ask his names, and of him that come\n",
            "to none, and rei \n",
            "\n",
            "GENERATED SAMPLE FOR: N\n",
            "Neborn song are to\n",
            "the king's law, and called them that four good before all truth:\n",
            "sentem when the L \n",
            "\n",
            "GENERATED SAMPLE FOR: O\n",
            "ORD my God, and that kill the nations also return, according to the water of the shoulder,\n",
            "and your s \n",
            "\n",
            "GENERATED SAMPLE FOR: P\n",
            "Perass it, and Moses took Talphatia, hithing shall bear him: or selled\n",
            "up to the ewe of Sleachen, who \n",
            "\n",
            "GENERATED SAMPLE FOR: Q\n",
            "Q/w of thy sake\n",
            "any thing than the morning affliction down used into the right house\n",
            "at Nebua: and Re \n",
            "\n",
            "GENERATED SAMPLE FOR: R\n",
            "RD wax commanded them, for the defil hath we say unto them, I have\n",
            "your bllowds shew thee a desert co \n",
            "\n",
            "GENERATED SAMPLE FOR: S\n",
            "Shaded Jerusalem, and kill the land of\n",
            "the wildrings with our bed, and the lefts of the understand th \n",
            "\n",
            "GENERATED SAMPLE FOR: T\n",
            "The law of the house of thy sackls; and thou\n",
            "art with the sabbath, and the twelve things, O the deeds \n",
            "\n",
            "GENERATED SAMPLE FOR: U\n",
            "Uungldment, and to kill\n",
            "their tents, to see the families of Hazael, and came, and walked also\n",
            "with fo \n",
            "\n",
            "GENERATED SAMPLE FOR: V\n",
            "Veration.\n",
            "\n",
            "74:9 Come like their seed were carried them that had not our eyes.\n",
            "\n",
            "15:19 The way of Dedep \n",
            "\n",
            "GENERATED SAMPLE FOR: W\n",
            "Whereins also had as oucheth down all the face of the people.\n",
            "\n",
            "53:6 The priest shall see the earth, w \n",
            "\n",
            "GENERATED SAMPLE FOR: X\n",
            "X not the land of the Gentiles, and the chamberlains of hosts unto Judah,\n",
            "14:13 And the half of the c \n",
            "\n",
            "GENERATED SAMPLE FOR: Y\n",
            "Ye went down against\n",
            "the glory of God.\n",
            "\n",
            "10:45 But he deceive it for ever: 10:17 The children of\n",
            "Israe \n",
            "\n",
            "GENERATED SAMPLE FOR: Z\n",
            "Zed.\n",
            "\n",
            "7:29 But all the children of Israel had dried the Onesh, and the\n",
            "ruling of the sons of Jebua.\n",
            "\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv3ETffp0qUg"
      },
      "source": [
        "# #4.5 Comparison between Bible vs. Shakespeare GRU\r\n",
        "- The loss was lower when we trained the GRU using the king James bible (~1.1 for bible vs. ~1.3 for shakespeare)\r\n",
        "- As for the realisticness of the samples, it is hard to compare the two because they have very different writing styles. However the bible GRU did learn how to use numbers (ie. 2:32) and does seem to generate realistic names of charecters in the bible. The shakespeare one, similarly, generates realisticly formated diaglouge and also generates realistic charecter names at times."
      ]
    }
  ]
}